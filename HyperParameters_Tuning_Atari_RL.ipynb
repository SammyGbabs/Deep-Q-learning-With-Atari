{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "670447a42c2a460a89f4954e7a6e4e06": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_ed021a485799427d9376549afd25f97d",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "\u001b[35m 100%\u001b[0m \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m \u001b[32m49,999/50,000 \u001b[0m [ \u001b[33m0:23:00\u001b[0m < \u001b[36m0:00:01\u001b[0m , \u001b[31m107 it/s\u001b[0m ]\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #f92672; text-decoration-color: #f92672\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸</span> <span style=\"color: #008000; text-decoration-color: #008000\">49,999/50,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:23:00</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:01</span> , <span style=\"color: #800000; text-decoration-color: #800000\">107 it/s</span> ]\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "ed021a485799427d9376549afd25f97d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SammyGbabs/Deep-Q-learning-With-Atari/blob/main/HyperParameters_Tuning_Atari_RL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stable-baselines3 gymnasium[atari] ale-py pyvirtualdisplay"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmWEXVqsIBGg",
        "outputId": "f2ce17d5-844e-49b7-a0c4-a0b659e0c446"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stable-baselines3\n",
            "  Downloading stable_baselines3-2.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: ale-py in /usr/local/lib/python3.11/dist-packages (0.10.2)\n",
            "Collecting pyvirtualdisplay\n",
            "  Downloading PyVirtualDisplay-3.0-py3-none-any.whl.metadata (943 bytes)\n",
            "Requirement already satisfied: gymnasium[atari] in /usr/local/lib/python3.11/dist-packages (1.1.1)\n",
            "Collecting gymnasium<1.1.0,>=0.29.1 (from stable-baselines3)\n",
            "  Downloading gymnasium-1.0.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (2.0.2)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (2.6.0+cu124)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (3.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (3.10.0)\n",
            "INFO: pip is looking at multiple versions of gymnasium[atari] to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting gymnasium[atari]\n",
            "  Downloading gymnasium-1.1.0-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[atari]) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium[atari]) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable-baselines3) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0,>=2.3->stable-baselines3) (3.0.2)\n",
            "Downloading stable_baselines3-2.5.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\n",
            "Downloading gymnasium-1.0.0-py3-none-any.whl (958 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m958.1/958.1 kB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m73.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m82.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyvirtualdisplay, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, gymnasium, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, stable-baselines3\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: gymnasium\n",
            "    Found existing installation: gymnasium 1.1.1\n",
            "    Uninstalling gymnasium-1.1.1:\n",
            "      Successfully uninstalled gymnasium-1.1.1\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed gymnasium-1.0.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pyvirtualdisplay-3.0 stable-baselines3-2.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Import Required Libraries**\n",
        "\n"
      ],
      "metadata": {
        "id": "FOUK8On5hTSq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gymnasium as gym\n",
        "from stable_baselines3 import DQN\n",
        "from stable_baselines3.common.callbacks import CheckpointCallback, EvalCallback\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "import ale_py\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "import numpy as np\n",
        "from gymnasium.wrappers import RecordVideo"
      ],
      "metadata": {
        "id": "-S4FIEkDfpW6"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Define the Breakout Agent Class and Create Environment and Model**\n"
      ],
      "metadata": {
        "id": "FEXPXo4bhg1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BreakoutAgent:\n",
        "    \"\"\"Handling the setup, execution, and training of the DQN agent\"\"\"\n",
        "\n",
        "    def __init__(self, model_directory=\"models\", log_dir=\"logs\", total_timesteps=50000):\n",
        "        \"\"\"Setting up the agent, including environment and model loading\"\"\"\n",
        "        self.model_directory = model_directory\n",
        "        self.log_dir = log_dir\n",
        "        self.total_timesteps = total_timesteps\n",
        "\n",
        "        # Creating directories if they don't exist\n",
        "        os.makedirs(self.model_directory, exist_ok=True)\n",
        "        os.makedirs(self.log_dir, exist_ok=True)\n",
        "\n",
        "        # Initialize environments\n",
        "        self.env = self._create_wrapped_env()\n",
        "        self.eval_env = self._create_wrapped_env()\n",
        "\n",
        "        # DQN model\n",
        "        self.model = self._initialize_model()\n",
        "\n",
        "    @staticmethod\n",
        "    def _create_env(render_mode=None):\n",
        "        \"\"\"Creating the Breakout environment\"\"\"\n",
        "        env = gym.make(\"ALE/Breakout-v5\", render_mode=render_mode)\n",
        "        env = Monitor(env)\n",
        "        return env\n",
        "\n",
        "    def _create_wrapped_env(self):\n",
        "        \"\"\"Vectorized environment\"\"\"\n",
        "        return DummyVecEnv([lambda: self._create_env()])\n",
        "\n",
        "    def _initialize_model(self):\n",
        "        \"\"\"Initializing the model\"\"\"\n",
        "        return DQN(\n",
        "            \"CnnPolicy\",\n",
        "            self.env,\n",
        "            learning_rate=1e-4,\n",
        "            buffer_size=10000,\n",
        "            learning_starts=1000,\n",
        "            batch_size=32,\n",
        "            gamma=0.99,\n",
        "            exploration_fraction=0.1,\n",
        "            exploration_initial_eps=1.0,\n",
        "            exploration_final_eps=0.05,\n",
        "            train_freq=4,\n",
        "            gradient_steps=1,\n",
        "            target_update_interval=1000,\n",
        "            verbose=1,\n",
        "            tensorboard_log=self.log_dir,\n",
        "        )\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"Training the DQN agent\"\"\"\n",
        "        checkpoint_callback = CheckpointCallback(\n",
        "            save_freq=10000, save_path=self.model_directory, name_prefix=\"dqn_breakout\"\n",
        "        )\n",
        "        eval_callback = EvalCallback(\n",
        "            self.eval_env,\n",
        "            best_model_save_path=f\"{self.model_directory}/best_model\",\n",
        "            log_path=self.log_dir,\n",
        "            eval_freq=10000,\n",
        "            deterministic=True,\n",
        "            render=False,\n",
        "        )\n",
        "\n",
        "        # Training\n",
        "        self.model.learn(\n",
        "            total_timesteps=self.total_timesteps,\n",
        "            callback=[checkpoint_callback, eval_callback],\n",
        "            progress_bar=True,\n",
        "        )\n",
        "\n",
        "        # Saving the trained model\n",
        "        self.model.save(f\"{self.model_directory}/policy.zip\")\n",
        "        print(f\"Training completed! Model saved as '{self.model_directory}/policy.zip'\")\n",
        "\n",
        "    def execute(self, episodes=5):\n",
        "        \"\"\"Allowing the agent to play the game for a set number of episodes\"\"\"\n",
        "        for ep in range(episodes):\n",
        "            observation = self.eval_env.reset()\n",
        "            total_points = 0\n",
        "            done = False\n",
        "\n",
        "            while not done:\n",
        "                # Selecting an action using the trained model\n",
        "                action, _ = self.model.predict(observation, deterministic=True)\n",
        "                observation, reward, done, _ = self.eval_env.step(action)\n",
        "                total_points += reward\n",
        "\n",
        "            print(f\"Episode {ep + 1}: Total Score: {total_points}\")\n",
        "\n",
        "        self.env.close()"
      ],
      "metadata": {
        "id": "6B4Q2F-Jftke"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training the Agent**"
      ],
      "metadata": {
        "id": "LcP6imkTgcxS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_agent():\n",
        "    \"\"\"Initialize, train, and evaluate the Breakout agent\"\"\"\n",
        "    trainer = BreakoutAgent(total_timesteps=50000)\n",
        "\n",
        "    # Train the agent\n",
        "    trainer.train()\n",
        "\n",
        "    # Evaluate the agent\n",
        "    trainer.execute(episodes=5)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_agent()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "670447a42c2a460a89f4954e7a6e4e06",
            "ed021a485799427d9376549afd25f97d"
          ]
        },
        "id": "ZVCY6Io8f0uA",
        "outputId": "21942fbf-4952-42a0-b080-afd7b9ccfdb9"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "Wrapping the env in a VecTransposeImage.\n",
            "Logging to logs/DQN_1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "670447a42c2a460a89f4954e7a6e4e06"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "/usr/local/lib/python3.11/dist-packages/ipywidgets/widgets/widget_output.py:111: DeprecationWarning: \n",
              "Kernel._parent_header is deprecated in ipykernel 6. Use .get_parent()\n",
              "  if ip and hasattr(ip, 'kernel') and hasattr(ip.kernel, '_parent_header'):\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/usr/local/lib/python3.11/dist-packages/ipywidgets/widgets/widget_output.py:111: DeprecationWarning: \n",
              "Kernel._parent_header is deprecated in ipykernel 6. Use .get_parent()\n",
              "  if ip and hasattr(ip, 'kernel') and hasattr(ip.kernel, '_parent_header'):\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 194      |\n",
            "|    ep_rew_mean      | 1.25     |\n",
            "|    exploration_rate | 0.853    |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 735      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 775      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 200      |\n",
            "|    ep_rew_mean      | 1.62     |\n",
            "|    exploration_rate | 0.695    |\n",
            "| time/               |          |\n",
            "|    episodes         | 8        |\n",
            "|    fps              | 279      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 1603     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000316 |\n",
            "|    n_updates        | 150      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 206      |\n",
            "|    ep_rew_mean      | 1.75     |\n",
            "|    exploration_rate | 0.53     |\n",
            "| time/               |          |\n",
            "|    episodes         | 12       |\n",
            "|    fps              | 249      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 2474     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000165 |\n",
            "|    n_updates        | 368      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 203      |\n",
            "|    ep_rew_mean      | 1.62     |\n",
            "|    exploration_rate | 0.383    |\n",
            "| time/               |          |\n",
            "|    episodes         | 16       |\n",
            "|    fps              | 235      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 3249     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 7.83e-05 |\n",
            "|    n_updates        | 562      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 212      |\n",
            "|    ep_rew_mean      | 1.7      |\n",
            "|    exploration_rate | 0.195    |\n",
            "| time/               |          |\n",
            "|    episodes         | 20       |\n",
            "|    fps              | 217      |\n",
            "|    time_elapsed     | 19       |\n",
            "|    total_timesteps  | 4239     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.03     |\n",
            "|    n_updates        | 809      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 252      |\n",
            "|    ep_rew_mean      | 1.79     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 24       |\n",
            "|    fps              | 198      |\n",
            "|    time_elapsed     | 30       |\n",
            "|    total_timesteps  | 6051     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00271  |\n",
            "|    n_updates        | 1262     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 282      |\n",
            "|    ep_rew_mean      | 1.89     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 28       |\n",
            "|    fps              | 188      |\n",
            "|    time_elapsed     | 41       |\n",
            "|    total_timesteps  | 7899     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00071  |\n",
            "|    n_updates        | 1724     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 279      |\n",
            "|    ep_rew_mean      | 1.81     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 32       |\n",
            "|    fps              | 186      |\n",
            "|    time_elapsed     | 47       |\n",
            "|    total_timesteps  | 8920     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000368 |\n",
            "|    n_updates        | 1979     |\n",
            "----------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Eval num_timesteps=10000, episode_reward=0.00 +/- 0.00\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=10000, episode_reward=0.00 +/- 0.00\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Episode length: 27000.00 +/- 0.00\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 27000.00 +/- 0.00\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------\n",
            "| eval/               |          |\n",
            "|    mean_ep_length   | 2.7e+04  |\n",
            "|    mean_reward      | 0        |\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    total_timesteps  | 10000    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000246 |\n",
            "|    n_updates        | 2249     |\n",
            "----------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "New best mean reward!\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">New best mean reward!\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 287      |\n",
            "|    ep_rew_mean      | 1.92     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 36       |\n",
            "|    fps              | 28       |\n",
            "|    time_elapsed     | 359      |\n",
            "|    total_timesteps  | 10336    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00152  |\n",
            "|    n_updates        | 2333     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 297      |\n",
            "|    ep_rew_mean      | 1.85     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 40       |\n",
            "|    fps              | 32       |\n",
            "|    time_elapsed     | 367      |\n",
            "|    total_timesteps  | 11873    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000296 |\n",
            "|    n_updates        | 2718     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 303      |\n",
            "|    ep_rew_mean      | 1.68     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 44       |\n",
            "|    fps              | 35       |\n",
            "|    time_elapsed     | 376      |\n",
            "|    total_timesteps  | 13326    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00169  |\n",
            "|    n_updates        | 3081     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 316      |\n",
            "|    ep_rew_mean      | 1.71     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 48       |\n",
            "|    fps              | 39       |\n",
            "|    time_elapsed     | 387      |\n",
            "|    total_timesteps  | 15166    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00187  |\n",
            "|    n_updates        | 3541     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 333      |\n",
            "|    ep_rew_mean      | 1.71     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 52       |\n",
            "|    fps              | 43       |\n",
            "|    time_elapsed     | 399      |\n",
            "|    total_timesteps  | 17311    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00143  |\n",
            "|    n_updates        | 4077     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 333      |\n",
            "|    ep_rew_mean      | 1.62     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 56       |\n",
            "|    fps              | 45       |\n",
            "|    time_elapsed     | 407      |\n",
            "|    total_timesteps  | 18663    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000931 |\n",
            "|    n_updates        | 4415     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 326      |\n",
            "|    ep_rew_mean      | 1.57     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 60       |\n",
            "|    fps              | 47       |\n",
            "|    time_elapsed     | 412      |\n",
            "|    total_timesteps  | 19556    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0002   |\n",
            "|    n_updates        | 4638     |\n",
            "----------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Eval num_timesteps=20000, episode_reward=0.00 +/- 0.00\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=20000, episode_reward=0.00 +/- 0.00\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Episode length: 27000.00 +/- 0.00\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 27000.00 +/- 0.00\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------\n",
            "| eval/               |          |\n",
            "|    mean_ep_length   | 2.7e+04  |\n",
            "|    mean_reward      | 0        |\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    total_timesteps  | 20000    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000657 |\n",
            "|    n_updates        | 4749     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 317      |\n",
            "|    ep_rew_mean      | 1.5      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64       |\n",
            "|    fps              | 28       |\n",
            "|    time_elapsed     | 715      |\n",
            "|    total_timesteps  | 20303    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000328 |\n",
            "|    n_updates        | 4825     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 308      |\n",
            "|    ep_rew_mean      | 1.46     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 68       |\n",
            "|    fps              | 29       |\n",
            "|    time_elapsed     | 718      |\n",
            "|    total_timesteps  | 20972    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 9.94e-05 |\n",
            "|    n_updates        | 4992     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 299      |\n",
            "|    ep_rew_mean      | 1.4      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 72       |\n",
            "|    fps              | 29       |\n",
            "|    time_elapsed     | 722      |\n",
            "|    total_timesteps  | 21561    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00602  |\n",
            "|    n_updates        | 5140     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 292      |\n",
            "|    ep_rew_mean      | 1.36     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 76       |\n",
            "|    fps              | 30       |\n",
            "|    time_elapsed     | 726      |\n",
            "|    total_timesteps  | 22190    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000243 |\n",
            "|    n_updates        | 5297     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 288      |\n",
            "|    ep_rew_mean      | 1.35     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 80       |\n",
            "|    fps              | 31       |\n",
            "|    time_elapsed     | 730      |\n",
            "|    total_timesteps  | 23006    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000668 |\n",
            "|    n_updates        | 5501     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 284      |\n",
            "|    ep_rew_mean      | 1.37     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 84       |\n",
            "|    fps              | 32       |\n",
            "|    time_elapsed     | 735      |\n",
            "|    total_timesteps  | 23863    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0023   |\n",
            "|    n_updates        | 5715     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 280      |\n",
            "|    ep_rew_mean      | 1.34     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 88       |\n",
            "|    fps              | 33       |\n",
            "|    time_elapsed     | 739      |\n",
            "|    total_timesteps  | 24620    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000899 |\n",
            "|    n_updates        | 5904     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 274      |\n",
            "|    ep_rew_mean      | 1.32     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 92       |\n",
            "|    fps              | 33       |\n",
            "|    time_elapsed     | 743      |\n",
            "|    total_timesteps  | 25238    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000644 |\n",
            "|    n_updates        | 6059     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 273      |\n",
            "|    ep_rew_mean      | 1.36     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 96       |\n",
            "|    fps              | 35       |\n",
            "|    time_elapsed     | 748      |\n",
            "|    total_timesteps  | 26211    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00163  |\n",
            "|    n_updates        | 6302     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 272      |\n",
            "|    ep_rew_mean      | 1.37     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 100      |\n",
            "|    fps              | 36       |\n",
            "|    time_elapsed     | 754      |\n",
            "|    total_timesteps  | 27241    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00167  |\n",
            "|    n_updates        | 6560     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 275      |\n",
            "|    ep_rew_mean      | 1.38     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 104      |\n",
            "|    fps              | 37       |\n",
            "|    time_elapsed     | 760      |\n",
            "|    total_timesteps  | 28287    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00405  |\n",
            "|    n_updates        | 6821     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 275      |\n",
            "|    ep_rew_mean      | 1.38     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 108      |\n",
            "|    fps              | 38       |\n",
            "|    time_elapsed     | 765      |\n",
            "|    total_timesteps  | 29102    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0038   |\n",
            "|    n_updates        | 7025     |\n",
            "----------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Eval num_timesteps=30000, episode_reward=2.20 +/- 0.98\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=30000, episode_reward=2.20 +/- 0.98\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Episode length: 10941.60 +/- 13111.64\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 10941.60 +/- 13111.64\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------\n",
            "| eval/               |          |\n",
            "|    mean_ep_length   | 1.09e+04 |\n",
            "|    mean_reward      | 2.2      |\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    total_timesteps  | 30000    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00265  |\n",
            "|    n_updates        | 7249     |\n",
            "----------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "New best mean reward!\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">New best mean reward!\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 276      |\n",
            "|    ep_rew_mean      | 1.41     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 112      |\n",
            "|    fps              | 33       |\n",
            "|    time_elapsed     | 894      |\n",
            "|    total_timesteps  | 30113    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000835 |\n",
            "|    n_updates        | 7278     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 276      |\n",
            "|    ep_rew_mean      | 1.42     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 116      |\n",
            "|    fps              | 34       |\n",
            "|    time_elapsed     | 898      |\n",
            "|    total_timesteps  | 30837    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00227  |\n",
            "|    n_updates        | 7459     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 274      |\n",
            "|    ep_rew_mean      | 1.39     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 120      |\n",
            "|    fps              | 35       |\n",
            "|    time_elapsed     | 903      |\n",
            "|    total_timesteps  | 31636    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00175  |\n",
            "|    n_updates        | 7658     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 263      |\n",
            "|    ep_rew_mean      | 1.35     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 124      |\n",
            "|    fps              | 35       |\n",
            "|    time_elapsed     | 907      |\n",
            "|    total_timesteps  | 32317    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00315  |\n",
            "|    n_updates        | 7829     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 256      |\n",
            "|    ep_rew_mean      | 1.41     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 128      |\n",
            "|    fps              | 36       |\n",
            "|    time_elapsed     | 914      |\n",
            "|    total_timesteps  | 33538    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00113  |\n",
            "|    n_updates        | 8134     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 254      |\n",
            "|    ep_rew_mean      | 1.41     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 132      |\n",
            "|    fps              | 37       |\n",
            "|    time_elapsed     | 919      |\n",
            "|    total_timesteps  | 34341    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00122  |\n",
            "|    n_updates        | 8335     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 248      |\n",
            "|    ep_rew_mean      | 1.35     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 136      |\n",
            "|    fps              | 37       |\n",
            "|    time_elapsed     | 924      |\n",
            "|    total_timesteps  | 35136    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00235  |\n",
            "|    n_updates        | 8533     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 240      |\n",
            "|    ep_rew_mean      | 1.34     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 140      |\n",
            "|    fps              | 38       |\n",
            "|    time_elapsed     | 929      |\n",
            "|    total_timesteps  | 35900    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00117  |\n",
            "|    n_updates        | 8724     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 238      |\n",
            "|    ep_rew_mean      | 1.46     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 144      |\n",
            "|    fps              | 39       |\n",
            "|    time_elapsed     | 937      |\n",
            "|    total_timesteps  | 37172    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0386   |\n",
            "|    n_updates        | 9042     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 233      |\n",
            "|    ep_rew_mean      | 1.53     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 148      |\n",
            "|    fps              | 40       |\n",
            "|    time_elapsed     | 944      |\n",
            "|    total_timesteps  | 38507    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00153  |\n",
            "|    n_updates        | 9376     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 223      |\n",
            "|    ep_rew_mean      | 1.6      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 152      |\n",
            "|    fps              | 41       |\n",
            "|    time_elapsed     | 951      |\n",
            "|    total_timesteps  | 39607    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00386  |\n",
            "|    n_updates        | 9651     |\n",
            "----------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Eval num_timesteps=40000, episode_reward=1.00 +/- 1.55\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=40000, episode_reward=1.00 +/- 1.55\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Episode length: 22412.20 +/- 9175.60\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 22412.20 +/- 9175.60\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------\n",
            "| eval/               |          |\n",
            "|    mean_ep_length   | 2.24e+04 |\n",
            "|    mean_reward      | 1        |\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    total_timesteps  | 40000    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0058   |\n",
            "|    n_updates        | 9749     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 218      |\n",
            "|    ep_rew_mean      | 1.69     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 156      |\n",
            "|    fps              | 33       |\n",
            "|    time_elapsed     | 1202     |\n",
            "|    total_timesteps  | 40435    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00207  |\n",
            "|    n_updates        | 9858     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 218      |\n",
            "|    ep_rew_mean      | 1.79     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 160      |\n",
            "|    fps              | 34       |\n",
            "|    time_elapsed     | 1208     |\n",
            "|    total_timesteps  | 41376    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000563 |\n",
            "|    n_updates        | 10093    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 220      |\n",
            "|    ep_rew_mean      | 1.86     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 164      |\n",
            "|    fps              | 34       |\n",
            "|    time_elapsed     | 1213     |\n",
            "|    total_timesteps  | 42272    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00493  |\n",
            "|    n_updates        | 10317    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 222      |\n",
            "|    ep_rew_mean      | 1.97     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 168      |\n",
            "|    fps              | 35       |\n",
            "|    time_elapsed     | 1218     |\n",
            "|    total_timesteps  | 43188    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0018   |\n",
            "|    n_updates        | 10546    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 226      |\n",
            "|    ep_rew_mean      | 2.09     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 172      |\n",
            "|    fps              | 36       |\n",
            "|    time_elapsed     | 1224     |\n",
            "|    total_timesteps  | 44171    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00231  |\n",
            "|    n_updates        | 10792    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 232      |\n",
            "|    ep_rew_mean      | 2.25     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 176      |\n",
            "|    fps              | 36       |\n",
            "|    time_elapsed     | 1231     |\n",
            "|    total_timesteps  | 45381    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00168  |\n",
            "|    n_updates        | 11095    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 234      |\n",
            "|    ep_rew_mean      | 2.34     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 180      |\n",
            "|    fps              | 37       |\n",
            "|    time_elapsed     | 1237     |\n",
            "|    total_timesteps  | 46363    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00188  |\n",
            "|    n_updates        | 11340    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 236      |\n",
            "|    ep_rew_mean      | 2.41     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 184      |\n",
            "|    fps              | 38       |\n",
            "|    time_elapsed     | 1243     |\n",
            "|    total_timesteps  | 47434    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00546  |\n",
            "|    n_updates        | 11608    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 237      |\n",
            "|    ep_rew_mean      | 2.5      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 188      |\n",
            "|    fps              | 38       |\n",
            "|    time_elapsed     | 1249     |\n",
            "|    total_timesteps  | 48369    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0039   |\n",
            "|    n_updates        | 11842    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 241      |\n",
            "|    ep_rew_mean      | 2.6      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 192      |\n",
            "|    fps              | 39       |\n",
            "|    time_elapsed     | 1254     |\n",
            "|    total_timesteps  | 49312    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.003    |\n",
            "|    n_updates        | 12077    |\n",
            "----------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Eval num_timesteps=50000, episode_reward=4.20 +/- 0.98\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=50000, episode_reward=4.20 +/- 0.98\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Episode length: 10968.80 +/- 13089.42\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 10968.80 +/- 13089.42\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------\n",
            "| eval/               |          |\n",
            "|    mean_ep_length   | 1.1e+04  |\n",
            "|    mean_reward      | 4.2      |\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    total_timesteps  | 50000    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0126   |\n",
            "|    n_updates        | 12249    |\n",
            "----------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "New best mean reward!\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">New best mean reward!\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed! Model saved as 'models/policy.zip'\n",
            "Episode 1: Total Score: [3.]\n",
            "Episode 2: Total Score: [4.]\n",
            "Episode 3: Total Score: [4.]\n",
            "Episode 4: Total Score: [2.]\n",
            "Episode 5: Total Score: [5.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Playing the game by the Agent and recording its Action**"
      ],
      "metadata": {
        "id": "m6ZVsbDig5m1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BreakoutAgent:\n",
        "    \"\"\"Handling the setup and execution for a Breakout game agent with recording support.\"\"\"\n",
        "\n",
        "    def __init__(self, model_file=\"models/policy.zip\", video_folder=\"videos/\"):\n",
        "        \"\"\"Setting up the agent, including environment, model loading, and video recording.\"\"\"\n",
        "        os.makedirs(video_folder, exist_ok=True)\n",
        "        gym.register_envs(ale_py)\n",
        "        self.env = RecordVideo(gym.make(\"ALE/Breakout-v5\", render_mode=\"rgb_array\"), video_folder)\n",
        "        self.model_file = model_file\n",
        "        self.model = self.load_model()\n",
        "\n",
        "    def load_model(self):\n",
        "        \"\"\"Loading the DQN agent.\"\"\"\n",
        "        if not os.path.exists(self.model_file):\n",
        "            raise FileNotFoundError(f\"Model file not found at: {self.model_file}\")\n",
        "        try:\n",
        "            print(f\"Attempting to load model from: {self.model_file}\")\n",
        "            model = DQN.load(self.model_file)\n",
        "            print(f\"Model loaded successfully from: {self.model_file}\")\n",
        "            return model\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to load model: {e}\")\n",
        "            raise RuntimeError(\"Check the model file\")\n",
        "\n",
        "    def execute(self, episodes=5):\n",
        "        \"\"\"Running the trained agent for a given number of episodes while recording.\"\"\"\n",
        "        for ep in range(episodes):\n",
        "            observation, _ = self.env.reset()\n",
        "            total_reward = 0\n",
        "            is_done = False\n",
        "            steps = 0\n",
        "\n",
        "            while not is_done:\n",
        "                action, _ = self.model.predict(observation, deterministic=True)\n",
        "                observation, reward, terminated, truncated, info = self.env.step(action)\n",
        "                total_reward += reward\n",
        "                steps += 1\n",
        "                is_done = terminated or truncated\n",
        "\n",
        "            print(f\"Episode {ep + 1}: Total Score: {total_reward} | Total Steps: {steps}\")\n",
        "\n",
        "        self.env.close()\n",
        "        print(\"Gameplay recorded successfully in the 'videos/' folder.\")\n",
        "\n",
        "\n",
        "def run_agent():\n",
        "    \"\"\"Initialization of the Breakout agent and execution.\"\"\"\n",
        "    trained_model = \"models/policy.zip\"\n",
        "    breakout_agent = BreakoutAgent(model_file=trained_model)\n",
        "    breakout_agent.execute(episodes=5)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_agent()"
      ],
      "metadata": {
        "id": "fO4jkj-nnpmC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}